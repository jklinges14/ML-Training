{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression¶\n",
    "Agenda\n",
    "Refresh your memory on how to do linear regression in scikit-learn\n",
    "Attempt to use linear regression for classification\n",
    "Show you why logistic regression is a better alternative for classification\n",
    "Brief overview of probability, odds, e, log, and log-odds\n",
    "Explain the form of logistic regression\n",
    "Explain how to interpret logistic regression coefficients\n",
    "Compare logistic regression with other models\n",
    "Part 1: Predicting a Continuous Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glass identification dataset\n",
    "import pandas as pd\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "col_names = ['id','ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass = pd.read_csv(url, names=col_names, index_col='id')\n",
    "glass['assorted'] = glass.glass_type.map({1:0, 2:0, 3:0, 4:0, 5:1, 6:1, 7:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretend that we want to predict ri, and our only feature is al. How would we do it using machine learning? We would frame it as a regression problem, and use a linear regression model with al as the only feature and ri as the response.\n",
    "\n",
    "How would we visualize this model? Create a scatter plot with al on the x-axis and ri on the y-axis, and draw the line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='al', y='ri', data=glass, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If we had an al value of 2, what would we predict for ri? Roughly 1.517.\n",
    "\n",
    "Exercise: Draw this plot without using Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot using Pandas\n",
    "glass.plot(kind='scatter', x='al', y='ri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot using Matplotlib\n",
    "plt.scatter(glass.al, glass.ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.ri\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the coefficients to get the equation for the line, but then how do you plot the line?\n",
    "print linreg.intercept_\n",
    "print linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could make predictions for arbitrary points, and then plot a line connecting them\n",
    "print linreg.predict(1)\n",
    "print linreg.predict(2)\n",
    "print linreg.predict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you could make predictions for all values of X, and then plot those predictions connected by a line\n",
    "ri_pred = linreg.predict(X)\n",
    "plt.plot(glass.al, ri_pred, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the plots together\n",
    "plt.scatter(glass.al, glass.ri)\n",
    "plt.plot(glass.al, ri_pred, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Refresher: interpreting linear regression coefficients\n",
    "Linear regression equation: $y = \\beta_0 + \\beta_1x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute prediction for al=2 using the equation\n",
    "linreg.intercept_ + linreg.coef_ * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute prediction for al=2 using the predict method\n",
    "linreg.predict(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine coefficient for al\n",
    "zip(feature_cols, linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation: A 1 unit increase in 'al' is associated with a 0.0025 unit decrease in 'ri'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing al by 1 (so that al=3) decreases ri by 0.0025\n",
    "1.51699012 - 0.0024776063874696243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute prediction for al=3 using the predict method\n",
    "linreg.predict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Part 2: Predicting a Categorical Response¶\n",
    "Let's change our task, so that we're predicting assorted using al. Let's visualize the relationship to figure out how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(glass.al, glass.assorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's draw a regression line, like we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear regression model and store the predictions\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.assorted\n",
    "linreg.fit(X, y)\n",
    "assorted_pred = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot that includes the regression line\n",
    "plt.scatter(glass.al, glass.assorted)\n",
    "plt.plot(glass.al, assorted_pred, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding np.where\n",
    "import numpy as np\n",
    "nums = np.array([5, 15, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where returns the first value if the condition is True, and the second value if the condition is False\n",
    "np.where(nums > 10, 'big', 'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the predictions\n",
    "assorted_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform predictions to 1 or 0\n",
    "assorted_pred_class = np.where(assorted_pred >= 0.5, 1, 0)\n",
    "assorted_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the class predictions\n",
    "plt.scatter(glass.al, glass.assorted)\n",
    "plt.plot(glass.al, assorted_pred_class, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predicted class to DataFrame\n",
    "glass['assorted_pred_class'] = assorted_pred_class\n",
    "\n",
    "# sort DataFrame by al\n",
    "glass.sort('al', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the class predictions again\n",
    "plt.scatter(glass.al, glass.assorted)\n",
    "plt.plot(glass.al, glass.assorted_pred_class, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Using Logistic Regression Instead¶\n",
    "Logistic regression can do what we just did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear regression model and store the class predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.assorted\n",
    "logreg.fit(X, y)\n",
    "assorted_pred_class = logreg.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the class predictions\n",
    "assorted_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the class predictions\n",
    "plt.scatter(glass.al, glass.assorted)\n",
    "plt.plot(glass.al, assorted_pred_class, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we wanted the predicted probabilities instead of just the class predictions, to understand how confident we are in a given prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilites of class 1\n",
    "assorted_pred_prob = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted probabilities\n",
    "plt.scatter(glass.al, glass.assorted)\n",
    "plt.plot(glass.al, assorted_pred_prob, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine some example predictions\n",
    "print logreg.predict_proba(1)\n",
    "print logreg.predict_proba(2)\n",
    "print logreg.predict_proba(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is this? The first column indicates the predicted probability of class 0, and the second column indicates the predicted probability of class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/justmarkham/DAT7/blob/master/notebooks/11_logistic_regression.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
